# Лабораторная работа 2: механизм распределения партиций по нодам кластера Apache Cassandra

# Ход работы

* Запускаем кластер cassandra в текущей конфигурации (один `seed` узел, один `worker` узел)
![image](https://user-images.githubusercontent.com/93330045/203517513-28daa242-e680-4fee-864a-ab0af5df02aa.png)

* С помощью запуска bash shell сессии в докер контейнере `seed` узла запускаем `nodetool status` и
  убеждаемся что кластер запущен и готов к работе (время инициализации кластера от одной до
  нескольких минут)
  ![image](https://user-images.githubusercontent.com/93330045/203516637-6b1c7e41-0659-48ef-8909-a26133f3152a.png)

* Каким образом сейчас распределены "токены" по узлам кластера?

100% токенов находятся на обеих нодах.

* Запускаем там же `cqlsh` сессию, создаём `KEYSPACE` и тестовую таблицу с книгами и авторами

![image](https://user-images.githubusercontent.com/93330045/203542925-ebc474ca-c60c-4495-9a7f-9499b8ce8400.png)

* Наполняем таблицу данными (можно написать скрпит который генерирует `INSERT` запросы, можно
  написать скрпит который подключается к Cassandra и вставляет туда записи, можно сделать вручную,
  как угодно)
  ![image](https://user-images.githubusercontent.com/93330045/203555155-71c44afa-3b53-4123-8a55-0deca2e4a841.png)

 
* После наполнения таблицы данными смотрим с помощью команды `nodetool getsstable test
  books_by_author "имя автора"` (имя автора - берем два три автора из ваших данных). Вероятнее
  всего, вывод будет пустым (почему это так? :) )

 Из-за того, что данные хранятся в оперативной памяти, а команда ищет данные на диске
 
* Запускаем команду `nodetool flush`, затем снова предыдущую - изменился ли вывод?
 ![image](https://user-images.githubusercontent.com/93330045/203555513-31458749-4bbe-4454-9bb3-fe0467499d9b.png)
 
Да, так как выполняется перенос данных на диск. 

* Смотрим на каких узлах кластера фактически расположены разбиения (partitions) для различных
  значений ключа разбиения (используем команду `nodetool getendpoints test books_by_author "имя
  автора"` для двух-трех случайно выбранных авторов)
  
100% токенов находятся на обеих нодах.
![image](https://user-images.githubusercontent.com/93330045/203559903-e4fbf532-0578-40f3-a684-3a1c019ffafc.png)

* Масштабируем кластер добавив к нему ещё один `worker` узел

docker compose up --scale worker_node=2 -d
![image](https://user-images.githubusercontent.com/93330045/203560511-9bbb8a0f-9cdc-4389-82ff-02975fb70951.png)

* Дожидаемся пока новый узел станет полноценной частью кластера (проверяем командой `nodetool
  status` с `seed` узла)
  
![image](https://user-images.githubusercontent.com/93330045/203562058-e565488c-1645-48f5-9a9f-744981e84a15.png)

  * Как теперь распределены "токены" по узлам кластера?
Равномерно

* Снова проверяем для тех же авторов каким образом теперь расположены на узлах кластера
  соответствующие разбиения (partitions)ons)
  
nodetool getendpoints test books_by_author 
