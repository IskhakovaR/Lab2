# Лабораторная работа 2: механизм распределения партиций по нодам кластера Apache Cassandra

# Ход работы

* Запускаем кластер cassandra в текущей конфигурации (один `seed` узел, один `worker` узел)
![image](https://user-images.githubusercontent.com/93330045/203517513-28daa242-e680-4fee-864a-ab0af5df02aa.png)

* С помощью запуска bash shell сессии в докер контейнере `seed` узла запускаем `nodetool status` и
  убеждаемся что кластер запущен и готов к работе (время инициализации кластера от одной до
  нескольких минут)
  ![image](https://user-images.githubusercontent.com/93330045/203516637-6b1c7e41-0659-48ef-8909-a26133f3152a.png)

* Каким образом сейчас распределены "токены" по узлам кластера?
100% токенов находятся на обеих нодах.
* Запускаем там же `cqlsh` сессию, создаём `KEYSPACE` и тестовую таблицу с книгами и авторами
* Наполняем таблицу данными (можно написать скрпит который генерирует `INSERT` запросы, можно
  написать скрпит который подключается к Cassandra и вставляет туда записи, можно сделать вручную,
  как угодно)
* После наполнения таблицы данными смотрим с помощью команды `nodetool getsstable test
  books_by_author "имя автора"` (имя автора - берем два три автора из ваших данных). Вероятнее
  всего, вывод будет пустым (почему это так? :) )
* Запускаем команду `nodetool flush`, затем снова предыдущую - изменился ли вывод?
* Смотрим на каких узлах кластера фактически расположены разбиения (partitions) для различных
  значений ключа разбиения (используем команду `nodetool getendpoints test books_by_author "имя
  автора"` для двух-трех случайно выбранных авторов)
* Масштабируем кластер добавив к нему ещё один `worker` узел
* Дожидаемся пока новый узел станет полноценной частью кластера (проверяем командой `nodetool
  status` с `seed` узла)
* Как теперь распределены "токены" по узлам кластера?
* Снова проверяем для тех же авторов каким образом теперь расположены на узлах кластера
  соответствующие разбиения (partitions)ons)
